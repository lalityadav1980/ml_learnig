{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as pandas, numpy, sklearn, tensorflow, and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Configure Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Logging\n",
    "Set up logging configuration to display information during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions for Technical Indicators\n",
    "Define functions to calculate technical indicators like SMA, EMA, RSI, ATR, Bollinger Bands, Momentum, ROC, Log Returns, High-Low Spread, and Open-Close Spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions for Technical Indicators\n",
    "\n",
    "def calculate_indicators(df):\n",
    "    logging.info(\"Calculating technical indicators...\")\n",
    "    df['SMA_10'] = df['close'].rolling(window=10).mean()\n",
    "    df['EMA_10'] = df['close'].ewm(span=10, adjust=False).mean()\n",
    "    df['RSI'] = calculate_rsi(df['close'])\n",
    "    df['ATR'] = calculate_atr(df)\n",
    "    df['Bollinger_Upper'], df['Bollinger_Lower'] = calculate_bollinger_bands(df['close'])\n",
    "    df['Momentum'] = df['close'] - df['close'].shift(10)\n",
    "    df['ROC'] = (df['close'] - df['close'].shift(10)) / df['close'].shift(10)\n",
    "    df['Log_Returns'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    df['High_Low_Spread'] = df['high'] - df['low']\n",
    "    df['Open_Close_Spread'] = df['open'] - df['close']\n",
    "    return df.dropna()\n",
    "\n",
    "def calculate_rsi(series, window=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_atr(df, window=14):\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = np.abs(df['high'] - df['close'].shift())\n",
    "    low_close = np.abs(df['low'] - df['close'].shift())\n",
    "    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    return true_range.rolling(window=window).mean()\n",
    "\n",
    "def calculate_bollinger_bands(series, window=20, num_sd=2):\n",
    "    sma = series.rolling(window=window).mean()\n",
    "    std = series.rolling(window=window).std()\n",
    "    upper_band = sma + (num_sd * std)\n",
    "    lower_band = sma - (num_sd * std)\n",
    "    return upper_band, lower_band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions for Data Preparation and Plotting\n",
    "Define functions to prepare LSTM input data, plot training loss, and plot predictions vs actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions for Data Preparation and Plotting\n",
    "\n",
    "def prepare_lstm_data(X, y, time_steps):\n",
    "    logging.info(\"Preparing LSTM input data...\")\n",
    "    X_lstm, y_lstm = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        X_lstm.append(X[i:i + time_steps])\n",
    "        y_lstm.append(y[i + time_steps])\n",
    "    return np.array(X_lstm), np.array(y_lstm)\n",
    "\n",
    "def plot_training_loss(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_predictions(y_actual, y_pred):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_actual, label='Actual Prices')\n",
    "    plt.plot(y_pred, label='Predicted Prices')\n",
    "    plt.title('Actual vs Predicted Prices')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Dataset\n",
    "Load the dataset, convert date column to datetime, and set it as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/NIFTY_100_minute.csv\")\n",
    "\n",
    "# Convert date column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Set date column as the index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Calculate technical indicators and add them as features to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate technical indicators and add them as features to the dataset\n",
    "df = calculate_indicators(df)\n",
    "\n",
    "# Display the first few rows of the dataframe with the new features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Use RandomForestRegressor and RFECV to select important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df.drop(columns=['close'])\n",
    "y = df['close']\n",
    "\n",
    "# Perform feature selection using RandomForestRegressor and RFECV\n",
    "rf = RandomForestRegressor()\n",
    "rfecv = RFECV(estimator=rf, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "# Select important features\n",
    "X_selected = X.iloc[:, rfecv.support_]\n",
    "\n",
    "# Display selected features\n",
    "X_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split\n",
    "Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scaling\n",
    "Scale the features using MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the first few rows of the scaled training data\n",
    "pd.DataFrame(X_train_scaled, columns=X_train.columns).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for LSTM\n",
    "Prepare the scaled data for LSTM model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for LSTM\n",
    "\n",
    "# Define the number of time steps\n",
    "time_steps = 10\n",
    "\n",
    "# Prepare the LSTM input data for training and testing sets\n",
    "X_train_lstm, y_train_lstm = prepare_lstm_data(X_train_scaled, y_train.values, time_steps)\n",
    "X_test_lstm, y_test_lstm = prepare_lstm_data(X_test_scaled, y_test.values, time_steps)\n",
    "\n",
    "# Display the shapes of the LSTM input data\n",
    "X_train_lstm.shape, y_train_lstm.shape, X_test_lstm.shape, y_test_lstm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train LSTM Model\n",
    "Build and train the LSTM model using the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Train LSTM Model\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the LSTM model\n",
    "history = model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, validation_data=(X_test_lstm, y_test_lstm), verbose=1)\n",
    "\n",
    "# Plot Training Loss\n",
    "plot_training_loss(history)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_lstm)\n",
    "y_test_actual = y_test_lstm\n",
    "y_pred_actual = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate Metrics\n",
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred_actual))\n",
    "logging.info(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "logging.info(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Plot Predictions\n",
    "plot_predictions(y_test_actual, y_pred_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model\n",
    "Evaluate the model's performance using metrics like MAE and RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_lstm)\n",
    "y_test_actual = y_test_lstm\n",
    "y_pred_actual = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate Metrics\n",
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred_actual))\n",
    "logging.info(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "logging.info(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Plot Predictions\n",
    "plot_predictions(y_test_actual, y_pred_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results\n",
    "Plot the training loss and predictions vs actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training Loss\n",
    "plot_training_loss(history)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_lstm)\n",
    "y_test_actual = y_test_lstm\n",
    "y_pred_actual = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate Metrics\n",
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred_actual))\n",
    "logging.info(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "logging.info(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Plot Predictions\n",
    "plot_predictions(y_test_actual, y_pred_actual)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
