{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNWnIJ7CjiT3///AmY5Vtpu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalityadav1980/ml_learnig/blob/main/ibm_quantum_live.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL6jK7SmjY6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149873fe-6cf7-4f88-d0f8-15a8cea70ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "Using device: cuda\n",
            "‚úÖ Successfully authenticated with IBM Quantum.\n",
            "Available Methods: ('automatic', 'statevector', 'density_matrix', 'stabilizer', 'matrix_product_state', 'extended_stabilizer', 'unitary', 'superop')\n",
            "Training on device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-32443209bbfa>:108: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n",
            "  local_sampler = Sampler()\n",
            "<ipython-input-1-32443209bbfa>:150: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Epoch [1/20] - Training Loss: 3.031900, Validation Loss: 1.312111\n",
            "üíæ Best model saved with validation loss: 1.312111\n",
            "üìà Epoch [2/20] - Training Loss: 3.031549, Validation Loss: 1.312050\n",
            "üíæ Best model saved with validation loss: 1.312050\n",
            "üìà Epoch [3/20] - Training Loss: 3.031549, Validation Loss: 1.312050\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.primitives import Sampler\n",
        "\n",
        "from qiskit_ibm_runtime import QiskitRuntimeService, Session, SamplerV2\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "\n",
        "import pandas as pd\n",
        "from qiskit_aer import Aer, AerSimulator\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "start_time = time.time()\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "# Add this line to define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "API_TOKEN = \"4ed9d81c24c1d6fb39f4f076976e930b0a0b57cf633303cafd3216068b4a268283b4a4bb0ca9d3ae6a787caf2b98fca3f4044a9051cb634ffb72f2eabdc6784b\"\n",
        "# === Authenticate and Connect to IBM Quantum Service ===\n",
        "try:\n",
        "    service = QiskitRuntimeService(\n",
        "        channel=\"ibm_quantum\",\n",
        "        token=API_TOKEN\n",
        "    )\n",
        "    print(\"‚úÖ Successfully authenticated with IBM Quantum.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Authentication failed: {e}\")\n",
        "# ================== Create Parametric Circuit ==================\n",
        "def create_quantum_circuit(num_qubits, num_features):\n",
        "    input_params = ParameterVector('x', length=num_features)\n",
        "    weight_params = ParameterVector('Œ∏', length=num_qubits * 8)  # Adjusted length\n",
        "\n",
        "    qc = QuantumCircuit(num_qubits)\n",
        "\n",
        "    # 1Ô∏è‚É£ Encode features\n",
        "    for i in range(num_features):\n",
        "        qc.rx(input_params[i], i % num_qubits)\n",
        "\n",
        "    # 2Ô∏è‚É£ Initial Variational Layer\n",
        "    for i in range(num_qubits):\n",
        "        qc.ry(weight_params[i], i)\n",
        "    for i in range(0, num_qubits, 2):\n",
        "        if i + 1 < num_qubits:\n",
        "            qc.cz(i, i + 1)\n",
        "    for i in range(num_qubits):\n",
        "        qc.rz(weight_params[num_qubits + i], i)\n",
        "\n",
        "    qc.barrier()  # Add barrier for clarity\n",
        "\n",
        "    # 3Ô∏è‚É£ Enhanced Variational Layers (Add More Layers for Higher Capacity)\n",
        "    for layer in range(3):  # Repeat 3 times for deeper layers\n",
        "        for i in range(num_qubits):\n",
        "            ry_idx = (2 + layer * 2) * num_qubits + i  # Dynamic index calculation\n",
        "            rz_idx = (3 + layer * 2) * num_qubits + i\n",
        "\n",
        "            qc.ry(weight_params[ry_idx], i)\n",
        "            qc.rz(weight_params[rz_idx], i)\n",
        "\n",
        "        # Add entanglement (circular CZ connections)\n",
        "        for i in range(num_qubits):\n",
        "            qc.cz(i, (i + 1) % num_qubits)  # Circular entanglement\n",
        "\n",
        "        qc.barrier()  # Optional: Improves circuit visualization\n",
        "\n",
        "    # 4Ô∏è‚É£ Measurement\n",
        "    qc.measure_all()\n",
        "\n",
        "    return qc, input_params, weight_params\n",
        "\n",
        "\n",
        "def process_last_records(historical_data, window_size=5):\n",
        "    \"\"\"\n",
        "    Process the last N historical records to prepare input for prediction.\n",
        "    \"\"\"\n",
        "    last_records = historical_data.tail(window_size)\n",
        "    return last_records.values.flatten().reshape(1, -1)\n",
        "\n",
        "\n",
        "def predict_next_draw(model, scaler, historical_data):\n",
        "    # Preprocess last N draws\n",
        "    input_data = process_last_records(historical_data)\n",
        "    scaled_data = scaler.transform(input_data)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        probs = model(torch.tensor(scaled_data, dtype=torch.float32))\n",
        "\n",
        "    return postprocess_predictions(probs.numpy()[0])\n",
        "\n",
        "\n",
        "# ================== Build Samplers ==================\n",
        "def build_local_simulator_sampler():\n",
        "    \"\"\"\n",
        "    Create a local simulator-based Sampler using Qiskit Primitives.\n",
        "    \"\"\"\n",
        "    simulator = AerSimulator(method='statevector')  # or 'qasm'\n",
        "    print(\"Available Methods:\", simulator.available_methods())\n",
        "    local_sampler = Sampler()\n",
        "    return local_sampler\n",
        "\n",
        "\n",
        "def build_hardware_sampler(num_qubits):\n",
        "    # Fetch available backends that are operational and meet qubit requirements\n",
        "    possible_backends = [\n",
        "        backend for backend in service.backends()\n",
        "        if (not backend.configuration().simulator and\n",
        "            backend.status().operational and\n",
        "            backend.configuration().num_qubits >= num_qubits)\n",
        "    ]\n",
        "\n",
        "    if not possible_backends:\n",
        "        raise ValueError(\"No operational real device found with enough qubits.\")\n",
        "\n",
        "    # Select the least busy backend\n",
        "    least_busy_backend = min(possible_backends, key=lambda b: b.status().pending_jobs)\n",
        "    print(f\"üîó Connecting to backend: {least_busy_backend.name}\")\n",
        "\n",
        "\n",
        "\n",
        "    # ‚úÖ Set shots using `default_shots`\n",
        "    hardware_sampler = SamplerV2(mode=least_busy_backend, options={\"default_shots\": 256})\n",
        "\n",
        "    return hardware_sampler\n",
        "\n",
        "\n",
        "# ================== Hybrid Model (Accepts Any Sampler) ==================\n",
        "class HybridQuantumNet(nn.Module):\n",
        "    def __init__(self, input_dim, num_qubits, sampler):\n",
        "        \"\"\"\n",
        "        Build a hybrid quantum-classical model that uses the given `sampler`,\n",
        "        which could be local or hardware-based.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. Create parametric circuit\n",
        "        qc, input_params, weight_params = create_quantum_circuit(num_qubits, input_dim)\n",
        "\n",
        "        # 2. Build QNN\n",
        "        self.quantum_nn = TorchConnector(\n",
        "            SamplerQNN(\n",
        "                circuit=qc,\n",
        "                input_params=input_params,\n",
        "                weight_params=weight_params,\n",
        "                sampler=sampler,  # local or hardware\n",
        "                input_gradients=True\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # 3. Classical network\n",
        "        # Now output 12 real numbers\n",
        "        self.classical_fc = nn.Sequential(\n",
        "            nn.Linear(16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 49),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quantum_nn(x)\n",
        "        return self.classical_fc(x)\n",
        "\n",
        "\n",
        "def create_sequences(data, window_size=5):\n",
        "    \"\"\"Create time-series sequences from historical data\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(data)):\n",
        "        X.append(data[i - window_size:i].flatten())  # Historical data\n",
        "        y.append(data[i][:7])  # Next draw's 7 numbers\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "# ================== Data Processing ==================\n",
        "def preprocess_data(data_path, window_size=5):\n",
        "    df = pd.read_csv(data_path)\n",
        "    numbers = df[[f\"winning_number_{i}\" for i in range(1, 7)] + [\"additional_number\"]].values\n",
        "    stats = df[[\"Low\", \"High\", \"Odd\", \"Even\", \"1-10\", \"11-20\", \"21-30\", \"31-40\", \"41-50\"]].values\n",
        "\n",
        "    X_seq, y_seq = create_sequences(numbers, window_size)\n",
        "    X_stats = stats[window_size:]\n",
        "\n",
        "    # Combine sequential data with statistical features\n",
        "    X = np.hstack([X_seq, X_stats])\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "    return train_test_split(scaler.fit_transform(X), y_seq, test_size=0.2)\n",
        "\n",
        "\n",
        "# ================== Training with Model Checkpoint ==================\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=20, checkpoint_path='best_model.pth'):\n",
        "    model = model.to(device)  # Move model to GPU\n",
        "    print(f\"Training on device: {device}\")\n",
        "    BATCH_SIZE = 64\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "        print(f\"‚úÖ Loaded pre-trained model from {checkpoint_path}.\")\n",
        "        return model\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    y_train_t = torch.tensor(y_train, dtype=torch.long).to(device)\n",
        "    X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "    y_val_t = torch.tensor(y_val, dtype=torch.long).to(device)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    best_val_loss = float('inf')\n",
        "    patience, counter = 5, 0\n",
        "\n",
        "    # Training loop with batches\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for i in range(0, len(X_train_t), BATCH_SIZE):\n",
        "            batch_X = X_train_t[i:i + BATCH_SIZE]\n",
        "            batch_y = y_train_t[i:i + BATCH_SIZE]\n",
        "\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y.argmax(dim=1))\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_pred = model(X_val_t)\n",
        "            val_pred_7 = val_pred[:, :7]\n",
        "            val_loss = criterion(val_pred_7, y_val_t.argmax(dim=1))\n",
        "\n",
        "        print(f\"üìà Epoch [{epoch + 1}/{epochs}] - Training Loss: {loss.item():.6f}, Validation Loss: {val_loss.item():.6f}\")\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "        if val_loss.item() < best_val_loss:\n",
        "            best_val_loss = val_loss.item()\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(f\"üíæ Best model saved with validation loss: {best_val_loss:.6f}\")\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(\"‚èπÔ∏è Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    print(\"‚úÖ Training completed successfully.\")\n",
        "    print(f\"‚è±Ô∏è Training completed in {time.time() - start_time:.2f} seconds\")\n",
        "    plot_loss(train_losses, val_losses)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# ================== Plotting Losses ==================\n",
        "def plot_loss(train_losses, val_losses):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
        "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()  # Use show() instead of savefig()\n",
        "\n",
        "\n",
        "# ================== Cache Quantum Model ==================\n",
        "def cache_quantum_model(model, cache_path='quantum_model_cache.pth'):\n",
        "    torch.save(model.state_dict(), cache_path)\n",
        "    print(f\"Quantum hardware model cached at {cache_path}.\")\n",
        "\n",
        "\n",
        "def load_cached_model(model, cache_path='quantum_model_cache.pth'):\n",
        "    if os.path.exists(cache_path):\n",
        "        model.load_state_dict(torch.load(cache_path))\n",
        "        print(f\"Loaded cached quantum model from {cache_path}\")\n",
        "    else:\n",
        "        print(f\"No cached model found at {cache_path}.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# ================== Prediction vs Actual Plot ==================\n",
        "def plot_predictions(predictions, actuals):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(predictions, label='Predicted', marker='o')\n",
        "    plt.plot(actuals, label='Actual', marker='x')\n",
        "    plt.xlabel('Sample Index')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title('Predictions vs Actuals')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ================== Postprocessing ==================\n",
        "def postprocess_predictions(probs, top_k=7):\n",
        "    \"\"\"Select numbers based on model confidence\"\"\"\n",
        "    numbers = np.arange(1, 50)\n",
        "    sorted_idx = np.argsort(-probs)  # Descending order\n",
        "    selected = []\n",
        "\n",
        "    for idx in sorted_idx:\n",
        "        num = numbers[idx]\n",
        "        if num not in selected:\n",
        "            selected.append(num)\n",
        "        if len(selected) == top_k:\n",
        "            break\n",
        "\n",
        "    return sorted(selected)\n",
        "\n",
        "\n",
        "# ================== Main Execution ==================\n",
        "def main():\n",
        "    DATA_PATH = \"/content/sample_data/ToTo.csv\"\n",
        "    NUM_QUBITS = 4\n",
        "\n",
        "    # 1Ô∏è‚É£ Load data\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(DATA_PATH)\n",
        "\n",
        "    # 2Ô∏è‚É£ Train with Simulator\n",
        "    local_sampler = build_local_simulator_sampler()\n",
        "    model_sim = HybridQuantumNet(\n",
        "        input_dim=X_train.shape[1],\n",
        "        num_qubits=NUM_QUBITS,\n",
        "        sampler=local_sampler\n",
        "    )\n",
        "    model_sim = train_model(model_sim, X_train, y_train, X_test, y_test, epochs=20)\n",
        "\n",
        "    # 3Ô∏è‚É£ Evaluate Predictions (Simulator)\n",
        "    with torch.no_grad():\n",
        "        predictions = model_sim(torch.tensor(X_test, dtype=torch.float32))[:, :7].numpy()\n",
        "\n",
        "    plot_predictions(predictions.flatten(), y_test.flatten())\n",
        "\n",
        "    # 4Ô∏è‚É£ Quantum Hardware Model (Cache if available)\n",
        "    hardware_sampler = build_hardware_sampler(NUM_QUBITS)\n",
        "    model_hw = HybridQuantumNet(\n",
        "        input_dim=X_train.shape[1],\n",
        "        num_qubits=NUM_QUBITS,\n",
        "        sampler=hardware_sampler\n",
        "    )\n",
        "\n",
        "    # Load cached model if exists\n",
        "    model_hw = load_cached_model(model_hw)\n",
        "\n",
        "    # If no cached model, train and save cache\n",
        "    if not os.path.exists(\"/content/drive/MyDrive/quantum_model_cache.pth\"):\n",
        "        model_hw.load_state_dict(model_sim.state_dict())  # Transfer learning\n",
        "        model_hw = train_model(model_hw, X_train, y_train, X_test, y_test, epochs=3)\n",
        "        cache_quantum_model(model_hw)\n",
        "\n",
        "    # 5Ô∏è‚É£ Final Predictions (Hardware)\n",
        "    with torch.no_grad():\n",
        "        hardware_predictions = model_hw(torch.tensor(X_test, dtype=torch.float32))[:, :7].numpy()\n",
        "\n",
        "    plot_predictions(hardware_predictions.flatten(), y_test.flatten())\n",
        "\n",
        "    # 6Ô∏è‚É£ üîÆ Predict the Next Draw Using Latest Historical Data\n",
        "    historical_data = pd.read_csv(DATA_PATH)\n",
        "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "    scaler.fit(X_train)  # Fit the scaler with training data for consistency\n",
        "\n",
        "    next_draw_prediction = predict_next_draw(model_hw, scaler, historical_data)\n",
        "    print(f\"üéØ Predicted Next Draw Numbers: {next_draw_prediction}\")\n",
        "\n",
        "main()"
      ]
    }
  ]
}