{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO8doHhhc+7sK1QhZO47RZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalityadav1980/ml_learnig/blob/main/ibm_new_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit qiskit-ibm-runtime qiskit-aer qiskit-machine-learning torch scikit-learn matplotlib pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rkBb0lxYyP8",
        "outputId": "7ca9ecf3-52aa-43e7-c085-f0290ae90f75"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: qiskit-ibm-runtime in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Requirement already satisfied: qiskit-aer in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: qiskit-machine-learning in /usr/local/lib/python3.11/dist-packages (0.8.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.16.0)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-runtime) (2.32.3)\n",
            "Requirement already satisfied: requests-ntlm>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-runtime) (1.3.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-runtime) (2.3.0)\n",
            "Requirement already satisfied: websocket-client>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-runtime) (1.8.0)\n",
            "Requirement already satisfied: ibm-platform-services>=0.22.6 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-runtime) (0.59.1)\n",
            "Requirement already satisfied: pydantic<2.10,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-runtime) (2.9.2)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-machine-learning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: ibm_cloud_sdk_core<4.0.0,>=3.22.0 in /usr/local/lib/python3.11/dist-packages (from ibm-platform-services>=0.22.6->qiskit-ibm-runtime) (3.22.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.10,>=2.5.0->qiskit-ibm-runtime) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.10,>=2.5.0->qiskit-ibm-runtime) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit-ibm-runtime) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit-ibm-runtime) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit-ibm-runtime) (2025.1.31)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.11/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime) (43.0.3)\n",
            "Requirement already satisfied: pyspnego>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime) (0.11.2)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime) (1.17.1)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from ibm_cloud_sdk_core<4.0.0,>=3.22.0->ibm-platform-services>=0.22.6->qiskit-ibm-runtime) (2.10.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL6jK7SmjY6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c95e0c-7dde-42bb-c77b-1b40b87c41b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "Using device: cuda\n",
            "✅ Successfully authenticated with IBM Quantum.\n",
            "Added sequence features with frequencies and presence indicators.\n",
            "Optimized: Added features for longer consecutive sequences without performance warnings.\n",
            "Cleaned Data: Removed 1 rows with empty or NaN values.\n",
            "Identified 336 feature columns.\n",
            "Available Methods: ('automatic', 'statevector', 'density_matrix', 'stabilizer', 'matrix_product_state', 'extended_stabilizer', 'unitary', 'superop')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b9eee394d412>:115: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n",
            "  local_sampler = Sampler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ┌──────────┐┌──────────┐ ┌──────────┐┌───────────┐┌───────────┐»\n",
            "   q_0: ┤ Rx(x[0]) ├┤ Rx(x[4]) ├─┤ Rx(x[8]) ├┤ Rx(x[12]) ├┤ Rx(x[16]) ├»\n",
            "        ├──────────┤├──────────┤ ├──────────┤├───────────┤├───────────┤»\n",
            "   q_1: ┤ Rx(x[1]) ├┤ Rx(x[5]) ├─┤ Rx(x[9]) ├┤ Rx(x[13]) ├┤ Rx(x[17]) ├»\n",
            "        ├──────────┤├──────────┤┌┴──────────┤├───────────┤├───────────┤»\n",
            "   q_2: ┤ Rx(x[2]) ├┤ Rx(x[6]) ├┤ Rx(x[10]) ├┤ Rx(x[14]) ├┤ Rx(x[18]) ├»\n",
            "        ├──────────┤├──────────┤├───────────┤├───────────┤├───────────┤»\n",
            "   q_3: ┤ Rx(x[3]) ├┤ Rx(x[7]) ├┤ Rx(x[11]) ├┤ Rx(x[15]) ├┤ Rx(x[19]) ├»\n",
            "        └──────────┘└──────────┘└───────────┘└───────────┘└───────────┘»\n",
            "meas: 4/═══════════════════════════════════════════════════════════════»\n",
            "                                                                       »\n",
            "«        ┌───────────┐┌───────────┐┌───────────┐┌───────────┐┌───────────┐»\n",
            "«   q_0: ┤ Rx(x[20]) ├┤ Rx(x[24]) ├┤ Rx(x[28]) ├┤ Rx(x[32]) ├┤ Rx(x[36]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_1: ┤ Rx(x[21]) ├┤ Rx(x[25]) ├┤ Rx(x[29]) ├┤ Rx(x[33]) ├┤ Rx(x[37]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_2: ┤ Rx(x[22]) ├┤ Rx(x[26]) ├┤ Rx(x[30]) ├┤ Rx(x[34]) ├┤ Rx(x[38]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_3: ┤ Rx(x[23]) ├┤ Rx(x[27]) ├┤ Rx(x[31]) ├┤ Rx(x[35]) ├┤ Rx(x[39]) ├»\n",
            "«        └───────────┘└───────────┘└───────────┘└───────────┘└───────────┘»\n",
            "«meas: 4/═════════════════════════════════════════════════════════════════»\n",
            "«                                                                         »\n",
            "«        ┌───────────┐┌───────────┐┌───────────┐┌───────────┐┌───────────┐»\n",
            "«   q_0: ┤ Rx(x[40]) ├┤ Rx(x[44]) ├┤ Rx(x[48]) ├┤ Rx(x[52]) ├┤ Rx(x[56]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_1: ┤ Rx(x[41]) ├┤ Rx(x[45]) ├┤ Rx(x[49]) ├┤ Rx(x[53]) ├┤ Rx(x[57]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_2: ┤ Rx(x[42]) ├┤ Rx(x[46]) ├┤ Rx(x[50]) ├┤ Rx(x[54]) ├┤ Rx(x[58]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_3: ┤ Rx(x[43]) ├┤ Rx(x[47]) ├┤ Rx(x[51]) ├┤ Rx(x[55]) ├┤ Rx(x[59]) ├»\n",
            "«        └───────────┘└───────────┘└───────────┘└───────────┘└───────────┘»\n",
            "«meas: 4/═════════════════════════════════════════════════════════════════»\n",
            "«                                                                         »\n",
            "«        ┌───────────┐┌───────────┐┌───────────┐┌───────────┐┌───────────┐»\n",
            "«   q_0: ┤ Rx(x[60]) ├┤ Rx(x[64]) ├┤ Rx(x[68]) ├┤ Rx(x[72]) ├┤ Rx(x[76]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_1: ┤ Rx(x[61]) ├┤ Rx(x[65]) ├┤ Rx(x[69]) ├┤ Rx(x[73]) ├┤ Rx(x[77]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_2: ┤ Rx(x[62]) ├┤ Rx(x[66]) ├┤ Rx(x[70]) ├┤ Rx(x[74]) ├┤ Rx(x[78]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_3: ┤ Rx(x[63]) ├┤ Rx(x[67]) ├┤ Rx(x[71]) ├┤ Rx(x[75]) ├┤ Rx(x[79]) ├»\n",
            "«        └───────────┘└───────────┘└───────────┘└───────────┘└───────────┘»\n",
            "«meas: 4/═════════════════════════════════════════════════════════════════»\n",
            "«                                                                         »\n",
            "«        ┌───────────┐┌───────────┐┌───────────┐┌───────────┐┌───────────┐»\n",
            "«   q_0: ┤ Rx(x[80]) ├┤ Rx(x[84]) ├┤ Rx(x[88]) ├┤ Rx(x[92]) ├┤ Rx(x[96]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_1: ┤ Rx(x[81]) ├┤ Rx(x[85]) ├┤ Rx(x[89]) ├┤ Rx(x[93]) ├┤ Rx(x[97]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_2: ┤ Rx(x[82]) ├┤ Rx(x[86]) ├┤ Rx(x[90]) ├┤ Rx(x[94]) ├┤ Rx(x[98]) ├»\n",
            "«        ├───────────┤├───────────┤├───────────┤├───────────┤├───────────┤»\n",
            "«   q_3: ┤ Rx(x[83]) ├┤ Rx(x[87]) ├┤ Rx(x[91]) ├┤ Rx(x[95]) ├┤ Rx(x[99]) ├»\n",
            "«        └───────────┘└───────────┘└───────────┘└───────────┘└───────────┘»\n",
            "«meas: 4/═════════════════════════════════════════════════════════════════»\n",
            "«                                                                         »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[100]) ├┤ Rx(x[104]) ├┤ Rx(x[108]) ├┤ Rx(x[112]) ├┤ Rx(x[116]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[101]) ├┤ Rx(x[105]) ├┤ Rx(x[109]) ├┤ Rx(x[113]) ├┤ Rx(x[117]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[102]) ├┤ Rx(x[106]) ├┤ Rx(x[110]) ├┤ Rx(x[114]) ├┤ Rx(x[118]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[103]) ├┤ Rx(x[107]) ├┤ Rx(x[111]) ├┤ Rx(x[115]) ├┤ Rx(x[119]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[120]) ├┤ Rx(x[124]) ├┤ Rx(x[128]) ├┤ Rx(x[132]) ├┤ Rx(x[136]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[121]) ├┤ Rx(x[125]) ├┤ Rx(x[129]) ├┤ Rx(x[133]) ├┤ Rx(x[137]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[122]) ├┤ Rx(x[126]) ├┤ Rx(x[130]) ├┤ Rx(x[134]) ├┤ Rx(x[138]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[123]) ├┤ Rx(x[127]) ├┤ Rx(x[131]) ├┤ Rx(x[135]) ├┤ Rx(x[139]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[140]) ├┤ Rx(x[144]) ├┤ Rx(x[148]) ├┤ Rx(x[152]) ├┤ Rx(x[156]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[141]) ├┤ Rx(x[145]) ├┤ Rx(x[149]) ├┤ Rx(x[153]) ├┤ Rx(x[157]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[142]) ├┤ Rx(x[146]) ├┤ Rx(x[150]) ├┤ Rx(x[154]) ├┤ Rx(x[158]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[143]) ├┤ Rx(x[147]) ├┤ Rx(x[151]) ├┤ Rx(x[155]) ├┤ Rx(x[159]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[160]) ├┤ Rx(x[164]) ├┤ Rx(x[168]) ├┤ Rx(x[172]) ├┤ Rx(x[176]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[161]) ├┤ Rx(x[165]) ├┤ Rx(x[169]) ├┤ Rx(x[173]) ├┤ Rx(x[177]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[162]) ├┤ Rx(x[166]) ├┤ Rx(x[170]) ├┤ Rx(x[174]) ├┤ Rx(x[178]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[163]) ├┤ Rx(x[167]) ├┤ Rx(x[171]) ├┤ Rx(x[175]) ├┤ Rx(x[179]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[180]) ├┤ Rx(x[184]) ├┤ Rx(x[188]) ├┤ Rx(x[192]) ├┤ Rx(x[196]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[181]) ├┤ Rx(x[185]) ├┤ Rx(x[189]) ├┤ Rx(x[193]) ├┤ Rx(x[197]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[182]) ├┤ Rx(x[186]) ├┤ Rx(x[190]) ├┤ Rx(x[194]) ├┤ Rx(x[198]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[183]) ├┤ Rx(x[187]) ├┤ Rx(x[191]) ├┤ Rx(x[195]) ├┤ Rx(x[199]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[200]) ├┤ Rx(x[204]) ├┤ Rx(x[208]) ├┤ Rx(x[212]) ├┤ Rx(x[216]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[201]) ├┤ Rx(x[205]) ├┤ Rx(x[209]) ├┤ Rx(x[213]) ├┤ Rx(x[217]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[202]) ├┤ Rx(x[206]) ├┤ Rx(x[210]) ├┤ Rx(x[214]) ├┤ Rx(x[218]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[203]) ├┤ Rx(x[207]) ├┤ Rx(x[211]) ├┤ Rx(x[215]) ├┤ Rx(x[219]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[220]) ├┤ Rx(x[224]) ├┤ Rx(x[228]) ├┤ Rx(x[232]) ├┤ Rx(x[236]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[221]) ├┤ Rx(x[225]) ├┤ Rx(x[229]) ├┤ Rx(x[233]) ├┤ Rx(x[237]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[222]) ├┤ Rx(x[226]) ├┤ Rx(x[230]) ├┤ Rx(x[234]) ├┤ Rx(x[238]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[223]) ├┤ Rx(x[227]) ├┤ Rx(x[231]) ├┤ Rx(x[235]) ├┤ Rx(x[239]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[240]) ├┤ Rx(x[244]) ├┤ Rx(x[248]) ├┤ Rx(x[252]) ├┤ Rx(x[256]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[241]) ├┤ Rx(x[245]) ├┤ Rx(x[249]) ├┤ Rx(x[253]) ├┤ Rx(x[257]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[242]) ├┤ Rx(x[246]) ├┤ Rx(x[250]) ├┤ Rx(x[254]) ├┤ Rx(x[258]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[243]) ├┤ Rx(x[247]) ├┤ Rx(x[251]) ├┤ Rx(x[255]) ├┤ Rx(x[259]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[260]) ├┤ Rx(x[264]) ├┤ Rx(x[268]) ├┤ Rx(x[272]) ├┤ Rx(x[276]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[261]) ├┤ Rx(x[265]) ├┤ Rx(x[269]) ├┤ Rx(x[273]) ├┤ Rx(x[277]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[262]) ├┤ Rx(x[266]) ├┤ Rx(x[270]) ├┤ Rx(x[274]) ├┤ Rx(x[278]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[263]) ├┤ Rx(x[267]) ├┤ Rx(x[271]) ├┤ Rx(x[275]) ├┤ Rx(x[279]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[280]) ├┤ Rx(x[284]) ├┤ Rx(x[288]) ├┤ Rx(x[292]) ├┤ Rx(x[296]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[281]) ├┤ Rx(x[285]) ├┤ Rx(x[289]) ├┤ Rx(x[293]) ├┤ Rx(x[297]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[282]) ├┤ Rx(x[286]) ├┤ Rx(x[290]) ├┤ Rx(x[294]) ├┤ Rx(x[298]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[283]) ├┤ Rx(x[287]) ├┤ Rx(x[291]) ├┤ Rx(x[295]) ├┤ Rx(x[299]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[300]) ├┤ Rx(x[304]) ├┤ Rx(x[308]) ├┤ Rx(x[312]) ├┤ Rx(x[316]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[301]) ├┤ Rx(x[305]) ├┤ Rx(x[309]) ├┤ Rx(x[313]) ├┤ Rx(x[317]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[302]) ├┤ Rx(x[306]) ├┤ Rx(x[310]) ├┤ Rx(x[314]) ├┤ Rx(x[318]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[303]) ├┤ Rx(x[307]) ├┤ Rx(x[311]) ├┤ Rx(x[315]) ├┤ Rx(x[319]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[320]) ├┤ Rx(x[324]) ├┤ Rx(x[328]) ├┤ Rx(x[332]) ├┤ Rx(x[336]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[321]) ├┤ Rx(x[325]) ├┤ Rx(x[329]) ├┤ Rx(x[333]) ├┤ Rx(x[337]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[322]) ├┤ Rx(x[326]) ├┤ Rx(x[330]) ├┤ Rx(x[334]) ├┤ Rx(x[338]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[323]) ├┤ Rx(x[327]) ├┤ Rx(x[331]) ├┤ Rx(x[335]) ├┤ Rx(x[339]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌────────────┐┌────────────┐»\n",
            "«   q_0: ┤ Rx(x[340]) ├┤ Rx(x[344]) ├┤ Rx(x[348]) ├┤ Rx(x[352]) ├┤ Rx(x[356]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_1: ┤ Rx(x[341]) ├┤ Rx(x[345]) ├┤ Rx(x[349]) ├┤ Rx(x[353]) ├┤ Rx(x[357]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_2: ┤ Rx(x[342]) ├┤ Rx(x[346]) ├┤ Rx(x[350]) ├┤ Rx(x[354]) ├┤ Rx(x[358]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├────────────┤├────────────┤»\n",
            "«   q_3: ┤ Rx(x[343]) ├┤ Rx(x[347]) ├┤ Rx(x[351]) ├┤ Rx(x[355]) ├┤ Rx(x[359]) ├»\n",
            "«        └────────────┘└────────────┘└────────────┘└────────────┘└────────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«        ┌────────────┐┌────────────┐┌────────────┐┌──────────┐   ┌──────────┐»\n",
            "«   q_0: ┤ Rx(x[360]) ├┤ Rx(x[364]) ├┤ Rx(x[368]) ├┤ Ry(θ[0]) ├─■─┤ Rz(θ[4]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├──────────┤ │ ├──────────┤»\n",
            "«   q_1: ┤ Rx(x[361]) ├┤ Rx(x[365]) ├┤ Rx(x[369]) ├┤ Ry(θ[1]) ├─■─┤ Rz(θ[5]) ├»\n",
            "«        ├────────────┤├────────────┤├────────────┤├──────────┤   ├──────────┤»\n",
            "«   q_2: ┤ Rx(x[362]) ├┤ Rx(x[366]) ├┤ Rx(x[370]) ├┤ Ry(θ[2]) ├─■─┤ Rz(θ[6]) ├»\n",
            "«        ├────────────┤├────────────┤└┬──────────┬┘└──────────┘ │ ├──────────┤»\n",
            "«   q_3: ┤ Rx(x[363]) ├┤ Rx(x[367]) ├─┤ Ry(θ[3]) ├──────────────■─┤ Rz(θ[7]) ├»\n",
            "«        └────────────┘└────────────┘ └──────────┘                └──────────┘»\n",
            "«meas: 4/═════════════════════════════════════════════════════════════════════»\n",
            "«                                                                             »\n",
            "«         ░  ┌──────────┐┌───────────┐             ░ ┌───────────┐┌───────────┐»\n",
            "«   q_0: ─░──┤ Ry(θ[8]) ├┤ Rz(θ[12]) ├─■────────■──░─┤ Ry(θ[16]) ├┤ Rz(θ[20]) ├»\n",
            "«         ░  ├──────────┤├───────────┤ │        │  ░ ├───────────┤├───────────┤»\n",
            "«   q_1: ─░──┤ Ry(θ[9]) ├┤ Rz(θ[13]) ├─■──■─────┼──░─┤ Ry(θ[17]) ├┤ Rz(θ[21]) ├»\n",
            "«         ░ ┌┴──────────┤├───────────┤    │     │  ░ ├───────────┤├───────────┤»\n",
            "«   q_2: ─░─┤ Ry(θ[10]) ├┤ Rz(θ[14]) ├────■──■──┼──░─┤ Ry(θ[18]) ├┤ Rz(θ[22]) ├»\n",
            "«         ░ ├───────────┤├───────────┤       │  │  ░ ├───────────┤├───────────┤»\n",
            "«   q_3: ─░─┤ Ry(θ[11]) ├┤ Rz(θ[15]) ├───────■──■──░─┤ Ry(θ[19]) ├┤ Rz(θ[23]) ├»\n",
            "«         ░ └───────────┘└───────────┘             ░ └───────────┘└───────────┘»\n",
            "«meas: 4/══════════════════════════════════════════════════════════════════════»\n",
            "«                                                                              »\n",
            "«                     ░ ┌───────────┐┌───────────┐             ░  ░ ┌─┐      »\n",
            "«   q_0: ─■────────■──░─┤ Ry(θ[24]) ├┤ Rz(θ[28]) ├─■────────■──░──░─┤M├──────»\n",
            "«         │        │  ░ ├───────────┤├───────────┤ │        │  ░  ░ └╥┘┌─┐   »\n",
            "«   q_1: ─■──■─────┼──░─┤ Ry(θ[25]) ├┤ Rz(θ[29]) ├─■──■─────┼──░──░──╫─┤M├───»\n",
            "«            │     │  ░ ├───────────┤├───────────┤    │     │  ░  ░  ║ └╥┘┌─┐»\n",
            "«   q_2: ────■──■──┼──░─┤ Ry(θ[26]) ├┤ Rz(θ[30]) ├────■──■──┼──░──░──╫──╫─┤M├»\n",
            "«               │  │  ░ ├───────────┤├───────────┤       │  │  ░  ░  ║  ║ └╥┘»\n",
            "«   q_3: ───────■──■──░─┤ Ry(θ[27]) ├┤ Rz(θ[31]) ├───────■──■──░──░──╫──╫──╫─»\n",
            "«                     ░ └───────────┘└───────────┘             ░  ░  ║  ║  ║ »\n",
            "«meas: 4/════════════════════════════════════════════════════════════╩══╩══╩═»\n",
            "«                                                                    0  1  2 »\n",
            "«           \n",
            "«   q_0: ───\n",
            "«           \n",
            "«   q_1: ───\n",
            "«           \n",
            "«   q_2: ───\n",
            "«        ┌─┐\n",
            "«   q_3: ┤M├\n",
            "«        └╥┘\n",
            "«meas: 4/═╩═\n",
            "«         3 \n",
            "Circuit depth: 115\n",
            "Gate counts: OrderedDict([('rx', 371), ('ry', 16), ('rz', 16), ('cz', 14), ('barrier', 5), ('measure', 4)])\n",
            "Training on device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b9eee394d412>:156: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  SamplerQNN(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.primitives import Sampler\n",
        "\n",
        "from qiskit_ibm_runtime import QiskitRuntimeService, Session, SamplerV2\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "\n",
        "import pandas as pd\n",
        "from qiskit_aer import Aer, AerSimulator\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "start_time = time.time()\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "# Add this line to define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "API_TOKEN = \"4ed9d81c24c1d6fb39f4f076976e930b0a0b57cf633303cafd3216068b4a268283b4a4bb0ca9d3ae6a787caf2b98fca3f4044a9051cb634ffb72f2eabdc6784b\"\n",
        "# === Authenticate and Connect to IBM Quantum Service ===\n",
        "try:\n",
        "    service = QiskitRuntimeService(\n",
        "        channel=\"ibm_quantum\",\n",
        "        token=API_TOKEN\n",
        "    )\n",
        "    print(\"✅ Successfully authenticated with IBM Quantum.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Authentication failed: {e}\")\n",
        "\n",
        "\n",
        "# ================== Create Parametric Circuit ==================\n",
        "def create_quantum_circuit(num_qubits, num_features):\n",
        "    # Define input and weight parameters\n",
        "    input_params = ParameterVector('x', length=num_features)\n",
        "    weight_params = ParameterVector('θ', length=num_qubits * 8)  # Adjusted for 3 layers\n",
        "\n",
        "    qc = QuantumCircuit(num_qubits)\n",
        "\n",
        "    # 1️⃣ Encode features\n",
        "    for i in range(num_features):\n",
        "        qc.rx(input_params[i], i % num_qubits)\n",
        "\n",
        "    # 2️⃣ Initial Variational Layer\n",
        "    for i in range(num_qubits):\n",
        "        qc.ry(weight_params[i], i)\n",
        "    for i in range(0, num_qubits, 2):\n",
        "        if i + 1 < num_qubits:\n",
        "            qc.cz(i, i + 1)\n",
        "    for i in range(num_qubits):\n",
        "        qc.rz(weight_params[num_qubits + i], i)\n",
        "\n",
        "    qc.barrier()  # Add barrier for clarity\n",
        "\n",
        "    # 3️⃣ Enhanced Variational Layers (Add More Layers for Higher Capacity)\n",
        "    for layer in range(3):  # Repeat 3 times for deeper layers\n",
        "        for i in range(num_qubits):\n",
        "            ry_idx = (2 + layer * 2) * num_qubits + i  # Dynamic index calculation\n",
        "            rz_idx = (3 + layer * 2) * num_qubits + i\n",
        "\n",
        "            qc.ry(weight_params[ry_idx], i)\n",
        "            qc.rz(weight_params[rz_idx], i)\n",
        "\n",
        "        # Add entanglement (circular CZ connections)\n",
        "        for i in range(num_qubits):\n",
        "            qc.cz(i, (i + 1) % num_qubits)  # Circular entanglement\n",
        "\n",
        "        qc.barrier()  # Optional: Improves circuit visualization\n",
        "\n",
        "    # 4️⃣ Measurement\n",
        "    qc.measure_all()\n",
        "\n",
        "    return qc, input_params, weight_params\n",
        "\n",
        "\n",
        "def process_last_records(historical_data, window_size=5):\n",
        "    \"\"\"\n",
        "    Process the last N historical records to prepare input for prediction.\n",
        "    \"\"\"\n",
        "    last_records = historical_data.tail(window_size)\n",
        "    return last_records.values.flatten().reshape(1, -1)\n",
        "\n",
        "\n",
        "# Modified predict_next_draw function\n",
        "def predict_next_draw(model, scaler, historical_data):\n",
        "    input_data = process_last_records(historical_data)\n",
        "    scaled_data = scaler.transform(input_data)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Move input to device and convert to float32\n",
        "        input_tensor = torch.tensor(scaled_data, dtype=torch.float32).to(device)\n",
        "        probs = model(input_tensor)\n",
        "\n",
        "    return postprocess_predictions(probs.cpu().numpy()[0])\n",
        "\n",
        "\n",
        "# ================== Build Samplers ==================\n",
        "def build_local_simulator_sampler():\n",
        "    \"\"\"\n",
        "    Create a local simulator-based Sampler using Qiskit Primitives.\n",
        "    \"\"\"\n",
        "    simulator = AerSimulator(method='statevector')  # or 'qasm'\n",
        "    print(\"Available Methods:\", simulator.available_methods())\n",
        "    local_sampler = Sampler()\n",
        "    return local_sampler\n",
        "\n",
        "\n",
        "def build_hardware_sampler(num_qubits):\n",
        "    # Fetch available backends that are operational and meet qubit requirements\n",
        "    possible_backends = [\n",
        "        backend for backend in service.backends()\n",
        "        if (not backend.configuration().simulator and\n",
        "            backend.status().operational and\n",
        "            backend.configuration().num_qubits >= num_qubits)\n",
        "    ]\n",
        "\n",
        "    if not possible_backends:\n",
        "        raise ValueError(\"No operational real device found with enough qubits.\")\n",
        "\n",
        "    # Select the least busy backend\n",
        "    least_busy_backend = min(possible_backends, key=lambda b: b.status().pending_jobs)\n",
        "    print(f\"🔗 Connecting to backend: {least_busy_backend.name}\")\n",
        "\n",
        "    # ✅ Set shots using `default_shots`\n",
        "    hardware_sampler = SamplerV2(mode=least_busy_backend, options={\"default_shots\": 256})\n",
        "\n",
        "    return hardware_sampler\n",
        "\n",
        "\n",
        "# ================== Hybrid Model (Accepts Any Sampler) ==================\n",
        "class HybridQuantumNet(nn.Module):\n",
        "    def __init__(self, input_dim, num_qubits, sampler):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. Create parametric circuit\n",
        "        qc, input_params, weight_params = create_quantum_circuit(num_qubits, input_dim)\n",
        "\n",
        "        # Print circuit details for debugging\n",
        "        print(qc.draw())\n",
        "        print(\"Circuit depth:\", qc.depth())\n",
        "        print(\"Gate counts:\", qc.count_ops())\n",
        "\n",
        "        # 2. Build QNN\n",
        "        self.quantum_nn = TorchConnector(\n",
        "            SamplerQNN(\n",
        "                circuit=qc,\n",
        "                input_params=input_params,\n",
        "                weight_params=weight_params,\n",
        "                sampler=sampler,  # local or hardware\n",
        "                input_gradients=True\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # 3. Classical network\n",
        "        self.classical_fc = nn.Sequential(\n",
        "            nn.Linear(2 ** num_qubits, 256),  # Match quantum output\n",
        "            nn.LeakyReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 49),\n",
        "            nn.Sigmoid()  # For multi-label classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quantum_nn(x)\n",
        "        return self.classical_fc(x)\n",
        "\n",
        "\n",
        "def create_sequences(data, window_size=5):\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(data)):\n",
        "        X.append(data[i - window_size:i].flatten())\n",
        "        # Create multi-hot encoding for 7 numbers\n",
        "        target = np.zeros(49)\n",
        "        for num in data[i][:7]:\n",
        "            target[num - 1] = 1  # Numbers 1-49 to indices 0-48\n",
        "        y.append(target)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# Utility Functions\n",
        "##############################################################################\n",
        "def compute_rolling_frequency_features(df: pd.DataFrame, window: int = 5, max_ball: int = 49) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Computes rolling frequency features for each lottery number.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Input DataFrame containing lottery numbers.\n",
        "    - window (int): Number of past draws to consider.\n",
        "    - max_ball (int): Maximum lottery number.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with added frequency features.\n",
        "    \"\"\"\n",
        "    df = df.copy().reset_index(drop=True)\n",
        "    numeric_cols = [c for c in df.columns if \"winning_number\" in c or \"additional_number\" in c]\n",
        "\n",
        "    for b in range(1, max_ball + 1):\n",
        "        df[f\"freq_{b}\"] = 0\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        start = max(0, i - window)\n",
        "        end = i  # Exclusive\n",
        "        recent_draws = df.iloc[start:end][numeric_cols]\n",
        "        counts = {k: 0 for k in range(1, max_ball + 1)}\n",
        "\n",
        "        for _, row in recent_draws.iterrows():\n",
        "            for val in row.values:\n",
        "                if val in counts:\n",
        "                    counts[val] += 1\n",
        "\n",
        "        for k in range(1, max_ball + 1):\n",
        "            df.at[i, f\"freq_{k}\"] = counts[k]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_sequence_features_with_numbers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Computes features related to sequences and gaps in the lottery numbers,\n",
        "    including the actual numbers in the sequences and their frequencies,\n",
        "    converted to Python integers.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Input DataFrame containing lottery numbers.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with added sequence and gap features.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    numeric_cols = [c for c in df.columns if \"winning_number\" in c or \"additional_number\" in c]\n",
        "\n",
        "    one_gap_numbers = []\n",
        "    all_one_gap_pairs = []  # To collect all unique one-gap pairs\n",
        "\n",
        "    for _, row in df[numeric_cols].iterrows():\n",
        "        numbers = sorted(row.values)  # Sort numbers for easier comparison\n",
        "        one_gap_nums = []\n",
        "\n",
        "        for i in range(len(numbers) - 1):\n",
        "            # One-gap numbers\n",
        "            if numbers[i + 1] - numbers[i] == 2:\n",
        "                pair = (int(numbers[i]), int(numbers[i + 1]))\n",
        "                one_gap_nums.append(pair)\n",
        "                all_one_gap_pairs.append(pair)\n",
        "\n",
        "        one_gap_numbers.append(one_gap_nums)\n",
        "\n",
        "    # Add counts and numbers as features\n",
        "    df[\"one_gap_numbers\"] = one_gap_numbers\n",
        "\n",
        "    # Identify unique one-gap pairs\n",
        "    unique_one_gap_pairs = set(all_one_gap_pairs)\n",
        "\n",
        "    # Calculate frequency and presence of each pair\n",
        "    for pair in unique_one_gap_pairs:\n",
        "        col_freq = f\"freq_{pair[0]}_{pair[1]}\"\n",
        "        col_has = f\"has_{pair[0]}_{pair[1]}\"\n",
        "\n",
        "        # Frequency of the pair in the entire dataset\n",
        "        freq = sum(pair in gaps for gaps in one_gap_numbers)\n",
        "\n",
        "        # Add columns for frequency and presence\n",
        "        df[col_freq] = df[\"one_gap_numbers\"].apply(lambda x: x.count(pair))\n",
        "        df[col_has] = df[\"one_gap_numbers\"].apply(lambda x: 1 if pair in x else 0)\n",
        "    df.drop(columns=[\"one_gap_numbers\"], inplace=True)\n",
        "    print(\"Added sequence features with frequencies and presence indicators.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_longer_consecutive_sequences(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    numeric_cols = [c for c in df.columns if \"winning_number\" in c or \"additional_number\" in c]\n",
        "\n",
        "    max_sequence_length = []\n",
        "    consecutive_sequences = []\n",
        "    sequence_counter = {}\n",
        "\n",
        "    for _, row in df[numeric_cols].iterrows():\n",
        "        numbers = sorted(row.values)\n",
        "        current_sequence = []\n",
        "        all_sequences = []\n",
        "        max_length = 0\n",
        "\n",
        "        for i in range(len(numbers)):\n",
        "            if i == 0 or numbers[i] - numbers[i - 1] == 1:\n",
        "                current_sequence.append(int(numbers[i]))\n",
        "            else:\n",
        "                if len(current_sequence) > 1:\n",
        "                    all_sequences.append(current_sequence)\n",
        "                    max_length = max(max_length, len(current_sequence))\n",
        "                current_sequence = [int(numbers[i])]\n",
        "\n",
        "        if len(current_sequence) > 1:\n",
        "            all_sequences.append(current_sequence)\n",
        "            max_length = max(max_length, len(current_sequence))\n",
        "\n",
        "        max_sequence_length.append(max_length)\n",
        "        consecutive_sequences.append(all_sequences)\n",
        "\n",
        "        # Count sequences\n",
        "        for seq in all_sequences:\n",
        "            key = '_'.join(map(str, seq))\n",
        "            sequence_counter[key] = sequence_counter.get(key, 0) + 1\n",
        "\n",
        "    # Add the sequences column temporarily\n",
        "    df[\"longer_consecutive_sequences\"] = consecutive_sequences\n",
        "\n",
        "    # Collect all new features in a dictionary\n",
        "    new_features = {}\n",
        "    for seq in sequence_counter:\n",
        "        freq_col = f\"freq_{seq}\"\n",
        "        has_col = f\"has_{seq}\"\n",
        "\n",
        "        freq_data = df[\"longer_consecutive_sequences\"].apply(\n",
        "            lambda x: sum(1 for s in x if '_'.join(map(str, s)) == seq)\n",
        "        )\n",
        "        has_data = freq_data.apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "        new_features[freq_col] = freq_data\n",
        "        new_features[has_col] = has_data\n",
        "\n",
        "    # Concatenate all new features at once\n",
        "    new_features_df = pd.DataFrame(new_features)\n",
        "    df = pd.concat([df, new_features_df], axis=1)\n",
        "\n",
        "    # Drop the temporary column\n",
        "    df.drop(columns=[\"longer_consecutive_sequences\"], inplace=True)\n",
        "\n",
        "    # Defragment the DataFrame\n",
        "    df = df.copy()\n",
        "\n",
        "    print(\"Optimized: Added features for longer consecutive sequences without performance warnings.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_even_odd_ratio(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Computes the ratio of even numbers in each draw.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Input DataFrame containing lottery numbers.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with added even-odd ratio feature.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    numeric_cols = [c for c in df.columns if \"winning_number\" in c or \"additional_number\" in c]\n",
        "\n",
        "    ratios = []\n",
        "    for _, row in df[numeric_cols].iterrows():\n",
        "        even_count = sum(n % 2 == 0 for n in row.values)\n",
        "        ratio = even_count / len(row.values)  # Out of 7\n",
        "        ratios.append(ratio)\n",
        "\n",
        "    df[\"even_odd_ratio\"] = ratios\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_hot_cold_numbers(df: pd.DataFrame, window: int = 10) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Computes hot and cold numbers based on their frequency in recent draws.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Input DataFrame containing lottery numbers.\n",
        "    - window (int): Number of past draws to consider.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with added hot and cold number features as separate columns.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    numeric_cols = [c for c in df.columns if \"winning_number\" in c or \"additional_number\" in c]\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        start = max(0, i - window)\n",
        "        end = i  # Exclusive\n",
        "        recent_draws = df.iloc[start:end][numeric_cols]\n",
        "        counts = recent_draws.stack().value_counts().to_dict()\n",
        "\n",
        "        # Hot numbers: most frequent in recent draws\n",
        "        hot_numbers = sorted(counts, key=counts.get, reverse=True)[:6]\n",
        "        # Cold numbers: least frequent in recent draws\n",
        "        cold_numbers = sorted(counts, key=counts.get)[:6]\n",
        "\n",
        "        # Add hot and cold numbers as separate columns\n",
        "        for j, num in enumerate(hot_numbers):\n",
        "            df.at[i, f\"hot_number_{j + 1}\"] = num\n",
        "        for j, num in enumerate(cold_numbers):\n",
        "            df.at[i, f\"cold_number_{j + 1}\"] = num\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_gaps_between_occurrences(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Computes the number of draws since each number last appeared.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Input DataFrame containing lottery numbers.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with added gap features.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    numeric_cols = [c for c in df.columns if \"winning_number\" in c or \"additional_number\" in c]\n",
        "\n",
        "    last_seen = {num: -1 for num in range(1, 50)}\n",
        "    gaps = []\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        row = df.iloc[i][numeric_cols]\n",
        "        current_gaps = []\n",
        "        for num in range(1, 50):\n",
        "            if num in row.values:\n",
        "                current_gaps.append(0)\n",
        "                last_seen[num] = i\n",
        "            else:\n",
        "                current_gaps.append(i - last_seen[num] if last_seen[num] != -1 else 0)\n",
        "        gaps.append(current_gaps)\n",
        "\n",
        "    gap_cols = [f\"gap_{num}\" for num in range(1, 50)]\n",
        "    df[gap_cols] = gaps\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_number_pairs_triplets(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Computes frequently occurring pairs and triplets of numbers.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Input DataFrame containing lottery numbers.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with added pair and triplet features.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    numeric_cols = [c for c in df.columns if \"winning_number\" in c or \"additional_number\" in c]\n",
        "\n",
        "    # Count pairs and triplets\n",
        "    pairs = {}\n",
        "    triplets = {}\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        row = df.iloc[i][numeric_cols].values\n",
        "        # Pairs\n",
        "        for j in range(len(row)):\n",
        "            for k in range(j + 1, len(row)):\n",
        "                pair = tuple(sorted((row[j], row[k])))\n",
        "                pairs[pair] = pairs.get(pair, 0) + 1\n",
        "        # Triplets\n",
        "        for j in range(len(row)):\n",
        "            for k in range(j + 1, len(row)):\n",
        "                for l in range(k + 1, len(row)):\n",
        "                    triplet = tuple(sorted((row[j], row[k], row[l])))\n",
        "                    triplets[triplet] = triplets.get(triplet, 0) + 1\n",
        "\n",
        "    # Add top pairs and triplets as features\n",
        "    top_pairs = sorted(pairs, key=pairs.get, reverse=True)[:5]\n",
        "    top_triplets = sorted(triplets, key=triplets.get, reverse=True)[:5]\n",
        "\n",
        "    for i, pair in enumerate(top_pairs):\n",
        "        df[f\"top_pair_{i + 1}\"] = \",\".join(map(str, pair))\n",
        "    for i, triplet in enumerate(top_triplets):\n",
        "        df[f\"top_triplet_{i + 1}\"] = \",\".join(map(str, triplet))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_statistical_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Computes statistical features (mean, std, skewness, kurtosis) for each draw.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Input DataFrame containing lottery numbers.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with added statistical features.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    numeric_cols = [c for c in df.columns if \"winning_number\" in c or \"additional_number\" in c]\n",
        "\n",
        "    df[\"mean\"] = df[numeric_cols].mean(axis=1)\n",
        "    df[\"std\"] = df[numeric_cols].std(axis=1)\n",
        "    df[\"skewness\"] = df[numeric_cols].apply(lambda x: skew(x), axis=1)\n",
        "    df[\"kurtosis\"] = df[numeric_cols].apply(lambda x: kurtosis(x), axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_feature_columns(df: pd.DataFrame) -> list:\n",
        "    \"\"\"\n",
        "    Identifies feature columns by excluding specific columns related to basic lottery information.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Input DataFrame.\n",
        "\n",
        "    Returns:\n",
        "    - List of feature columns.\n",
        "    \"\"\"\n",
        "    # ✅ Columns to exclude\n",
        "    exclude_cols = [\n",
        "        \"Date_numeric\",\n",
        "        \"winning_number_1\", \"winning_number_2\", \"winning_number_3\",\n",
        "        \"winning_number_4\", \"winning_number_5\", \"winning_number_6\",\n",
        "        \"additional_number\"\n",
        "    ]\n",
        "\n",
        "    # 🚀 Automatically detect all other feature columns\n",
        "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
        "\n",
        "    print(f\"Identified {len(feature_cols)} feature columns.\")\n",
        "    return feature_cols\n",
        "\n",
        "\n",
        "# ================== Data Processing ==================\n",
        "def preprocess_data(data_path, window_size=5):\n",
        "    \"\"\"\n",
        "    Preprocess the data and split it into training, validation, and test sets.\n",
        "    Computes additional statistical features and saves the splits into separate CSV files.\n",
        "    \"\"\"\n",
        "    # Load and sort data by date\n",
        "    df = pd.read_csv(data_path).sort_values('Date', ascending=True).reset_index(drop=True)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%y\", errors=\"coerce\")\n",
        "    df[\"Date_numeric\"] = df[\"Date\"].astype(\"int64\") // 1e9\n",
        "    df.drop(columns=[\"Date\"], inplace=True)\n",
        "\n",
        "    # Apply statistical functions to the DataFrame\n",
        "    #df = compute_rolling_frequency_features(df, window=window_size)\n",
        "    df = compute_sequence_features_with_numbers(df)\n",
        "    df = compute_longer_consecutive_sequences(df)\n",
        "\n",
        "    df = compute_even_odd_ratio(df)\n",
        "    df = compute_hot_cold_numbers(df, window=window_size)\n",
        "    df = compute_statistical_features(df)\n",
        "\n",
        "    # ✅ Remove rows with any NaN or empty values\n",
        "    df = df.dropna()  # Remove rows with NaN values\n",
        "    df = df[~(df == '').any(axis=1)]  # Remove rows with empty string values\n",
        "\n",
        "    print(f\"Cleaned Data: Removed {len(pd.read_csv(data_path)) - len(df)} rows with empty or NaN values.\")\n",
        "\n",
        "\n",
        "    pd.DataFrame(df).to_csv(\"/content/sample_data/fetaure_processed.csv\", index=False)\n",
        "    # Calculate split indices\n",
        "    total_samples = len(df)\n",
        "    train_size = int(total_samples * 0.8)  # 80% for training\n",
        "    val_size = int(total_samples * 0.1)  # 10% for validation\n",
        "    test_size = total_samples - train_size - val_size  # Remaining 10% for testing\n",
        "\n",
        "    # Split data into training, validation, and test sets\n",
        "    train_df = df.iloc[:train_size]\n",
        "    val_df = df.iloc[train_size:train_size + val_size]\n",
        "    test_df = df.iloc[train_size + val_size:]\n",
        "\n",
        "    # Save splits to separate CSV files\n",
        "    train_df.to_csv(\"/content/sample_data/training_data.csv\", index=False)\n",
        "    val_df.to_csv(\"/content/sample_data/validation_data.csv\", index=False)\n",
        "    test_df.to_csv(\"/content/sample_data/test_data.csv\", index=False)\n",
        "\n",
        "    # Select new statistical feature columns\n",
        "    feature_cols = get_feature_columns(df)\n",
        "\n",
        "    # Process features for each split\n",
        "    def process_split(split_df, is_train=False, train_df=None):\n",
        "        if is_train:\n",
        "            numbers = split_df[[f\"winning_number_{i}\" for i in range(1, 7)] + [\"additional_number\"]].values\n",
        "            stats = split_df[feature_cols].values\n",
        "        else:\n",
        "            combined_df = pd.concat([train_df, split_df], axis=0).reset_index(drop=True)\n",
        "            numbers = combined_df[[f\"winning_number_{i}\" for i in range(1, 7)] + [\"additional_number\"]].values\n",
        "            stats = combined_df[feature_cols].values\n",
        "\n",
        "        # Create sequences and features\n",
        "        X_seq, y_seq = create_sequences(numbers, window_size)\n",
        "        X_stats = stats[window_size:]\n",
        "\n",
        "        return np.hstack([X_seq, X_stats]), y_seq\n",
        "\n",
        "    # Process training data\n",
        "    X_train, y_train = process_split(train_df, is_train=True)\n",
        "\n",
        "    # Process validation data\n",
        "    X_val, y_val = process_split(val_df, train_df=train_df)\n",
        "\n",
        "    # Process test data\n",
        "    X_test, y_test = process_split(test_df, train_df=pd.concat([train_df, val_df], axis=0))\n",
        "    pd.DataFrame(X_test).to_csv(\"/content/sample_data/X_test_processed.csv\", index=False)\n",
        "    pd.DataFrame(y_test).to_csv(\"/content/sample_data/y_test_processed.csv\", index=False)\n",
        "\n",
        "    # Fit scaler on training data only\n",
        "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "\n",
        "# ================== Training with Model Checkpoint ==================\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=10, checkpoint_path='best_model.pth'):\n",
        "    # Move model to the appropriate device\n",
        "    model = model.to(device)\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    BATCH_SIZE = 64\n",
        "\n",
        "    # Load pre-trained model if available\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "        print(f\"✅ Loaded pre-trained model from {checkpoint_path}.\")\n",
        "        return model\n",
        "\n",
        "    # Define loss function, optimizer, and scheduler\n",
        "    criterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
        "\n",
        "    # Convert input data to tensors and move to device\n",
        "    X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)  # Targets must be float for BCEWithLogitsLoss\n",
        "    X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "    y_val_t = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    best_val_loss = float('inf')\n",
        "    patience, counter = 5, 0\n",
        "    min_delta = 0.001  # Minimum improvement threshold\n",
        "    overfit_threshold = 0.1  # Maximum allowed gap between training and validation loss\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "\n",
        "        # Mini-batch training\n",
        "        for i in range(0, len(X_train_t), BATCH_SIZE):\n",
        "            # Get batch\n",
        "            batch_X = X_train_t[i:i + BATCH_SIZE]\n",
        "            batch_y = y_train_t[i:i + BATCH_SIZE]\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)  # Use batch_y directly (no argmax)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "        # Calculate average training loss for the epoch\n",
        "        avg_train_loss = epoch_train_loss / (len(X_train_t) // BATCH_SIZE + 1)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val_t)\n",
        "            val_loss = criterion(val_outputs, y_val_t)  # Use full validation outputs\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "        # Print epoch statistics\n",
        "        print(\n",
        "            f\"📈 Epoch [{epoch + 1}/{epochs}] - Training Loss: {avg_train_loss:.6f}, Validation Loss: {val_loss.item():.6f}\")\n",
        "\n",
        "        # Update learning rate scheduler\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Check for early stopping conditions\n",
        "        if val_loss.item() < best_val_loss - min_delta:\n",
        "            best_val_loss = val_loss.item()\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(f\"💾 Best model saved with validation loss: {best_val_loss:.6f}\")\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(\"⏹️ Early stopping triggered due to lack of improvement.\")\n",
        "                break\n",
        "\n",
        "        # Check for overfitting\n",
        "        if avg_train_loss - val_loss.item() > overfit_threshold:\n",
        "            print(\"⏹️ Overfitting detected. Stopping training.\")\n",
        "            break\n",
        "\n",
        "    print(\"✅ Training completed successfully.\")\n",
        "    print(f\"⏱️ Training completed in {time.time() - start_time:.2f} seconds\")\n",
        "    plot_loss(train_losses, val_losses)\n",
        "    return model\n",
        "\n",
        "\n",
        "# ================== Plotting Losses ==================\n",
        "def plot_loss(train_losses, val_losses):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
        "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()  # Use show() instead of savefig()\n",
        "\n",
        "\n",
        "# ================== Cache Quantum Model ==================\n",
        "def cache_quantum_model(model, cache_path='quantum_model_cache.pth'):\n",
        "    torch.save(model.state_dict(), cache_path)\n",
        "    print(f\"Quantum hardware model cached at {cache_path}.\")\n",
        "\n",
        "\n",
        "def load_cached_model(model, cache_path='quantum_model_cache.pth'):\n",
        "    if os.path.exists(cache_path):\n",
        "        model.load_state_dict(torch.load(cache_path))\n",
        "        print(f\"Loaded cached quantum model from {cache_path}\")\n",
        "    else:\n",
        "        print(f\"No cached model found at {cache_path}.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# ================== Prediction vs Actual Plot ==================\n",
        "def plot_predictions(predictions, actuals):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(predictions, label='Predicted', marker='o')\n",
        "    plt.plot(actuals, label='Actual', marker='x')\n",
        "    plt.xlabel('Sample Index')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title('Predictions vs Actuals')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ================== Postprocessing ==================\n",
        "def postprocess_predictions(probs, top_k=7):\n",
        "    \"\"\"Select numbers based on model confidence\"\"\"\n",
        "    numbers = np.arange(1, 50)\n",
        "    sorted_idx = np.argsort(-probs)  # Descending order\n",
        "    selected = []\n",
        "\n",
        "    for idx in sorted_idx:\n",
        "        num = numbers[idx]\n",
        "        if num not in selected:\n",
        "            selected.append(num)\n",
        "        if len(selected) == top_k:\n",
        "            break\n",
        "\n",
        "    return sorted(selected)\n",
        "\n",
        "\n",
        "# ================== Main Execution ==================\n",
        "def main():\n",
        "    DATA_PATH = \"/content/sample_data/ToTo.csv\"\n",
        "    NUM_QUBITS = 4\n",
        "\n",
        "    # 1️⃣ Load data\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = preprocess_data(DATA_PATH)\n",
        "\n",
        "    # 2️⃣ Train with Simulator\n",
        "    local_sampler = build_local_simulator_sampler()\n",
        "    model_sim = HybridQuantumNet(\n",
        "        input_dim=X_train.shape[1],\n",
        "        num_qubits=NUM_QUBITS,\n",
        "        sampler=local_sampler\n",
        "    )\n",
        "    model_sim = train_model(model_sim, X_train, y_train, X_test, y_test, epochs=10)\n",
        "\n",
        "    # Modified evaluation section in main()\n",
        "    # 3️⃣ Evaluate Predictions (Simulator)\n",
        "    with torch.no_grad():\n",
        "        test_input = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "        predictions = model_sim(test_input)[:, :7].cpu().numpy()\n",
        "\n",
        "    plot_predictions(predictions.flatten(), y_test.flatten())\n",
        "\n",
        "    # 4️⃣ Quantum Hardware Model (Cache if available)\n",
        "    hardware_sampler = build_hardware_sampler(NUM_QUBITS)\n",
        "    model_hw = HybridQuantumNet(\n",
        "        input_dim=X_train.shape[1],\n",
        "        num_qubits=NUM_QUBITS,\n",
        "        sampler=hardware_sampler\n",
        "    )\n",
        "\n",
        "    # Load cached model if exists\n",
        "    model_hw = load_cached_model(model_hw)\n",
        "\n",
        "    # If no cached model, train and save cache\n",
        "    if not os.path.exists(\"/content/drive/MyDrive/quantum_model_cache.pth\"):\n",
        "        model_hw.load_state_dict(model_sim.state_dict())  # Transfer learning\n",
        "        model_hw = train_model(model_hw, X_train, y_train, X_test, y_test, epochs=3)\n",
        "        cache_quantum_model(model_hw)\n",
        "\n",
        "    # 5️⃣ Final Predictions (Hardware)\n",
        "    with torch.no_grad():\n",
        "        hardware_predictions = model_sim(torch.tensor(X_test, dtype=torch.float32).to(device))[:, :7].cpu().numpy()\n",
        "\n",
        "    plot_predictions(hardware_predictions.flatten(), y_test.flatten())\n",
        "\n",
        "    # 6️⃣ 🔮 Predict the Next Draw Using Latest Historical Data\n",
        "    historical_data = pd.read_csv(DATA_PATH)\n",
        "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "    scaler.fit(X_train)  # Fit the scaler with training data for consistency\n",
        "\n",
        "    next_draw_prediction = predict_next_draw(model_hw, scaler, historical_data)\n",
        "    print(f\"🎯 Predicted Next Draw Numbers: {next_draw_prediction}\")\n",
        "\n",
        "\n",
        "main()\n"
      ]
    }
  ]
}